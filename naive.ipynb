{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Georg\\anaconda3\\envs\\steam_analysis\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.5 when it was built against 1.14.6, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory \n",
    "folder_0 = os.path.join(os.getcwd(), 'resized_images', '0')\n",
    "folder_1 = os.path.join(os.getcwd(), 'resized_images', '1')\n",
    "folder_2 = os.path.join(os.getcwd(), 'resized_images', '2')\n",
    "folder_3 = os.path.join(os.getcwd(), 'resized_images', '3')\n",
    "folder_4 = os.path.join(os.getcwd(), 'resized_images', '4')\n",
    "folder_5 = os.path.join(os.getcwd(), 'resized_images', '5')\n",
    "folder_6 = os.path.join(os.getcwd(), 'resized_images', '6')\n",
    "folder_7 = os.path.join(os.getcwd(), 'resized_images', '7')\n",
    "folder_8 = os.path.join(os.getcwd(), 'resized_images', '8')\n",
    "folder_9 = os.path.join(os.getcwd(), 'resized_images', '9')\n",
    "folder_10 = os.path.join(os.getcwd(), 'resized_images', '10')\n",
    "folder_11 = os.path.join(os.getcwd(), 'resized_images', '11')\n",
    "folder_12 = os.path.join(os.getcwd(), 'resized_images', '12')\n",
    "folder_13 = os.path.join(os.getcwd(), 'resized_images', '13')\n",
    "folder_14 = os.path.join(os.getcwd(), 'resized_images', '14')\n",
    "folder_15 = os.path.join(os.getcwd(), 'resized_images', '15')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 12 images from class 0\n",
      "Loading 12 images from class 1\n",
      "Loading 12 images from class 2\n",
      "Loading 12 images from class 3\n",
      "Loading 12 images from class 4\n",
      "Loading 12 images from class 5\n",
      "Loading 12 images from class 6\n",
      "Loading 12 images from class 7\n",
      "Loading 12 images from class 8\n",
      "Loading 12 images from class 9\n",
      "Loading 12 images from class 10\n",
      "Loading 12 images from class 11\n",
      "Loading 12 images from class 12\n",
      "Loading 12 images from class 13\n",
      "Loading 12 images from class 14\n",
      "Loading 12 images from class 15\n",
      "Loaded 192 images with shape (192, 1000, 660, 3)\n",
      "Labels shape: (192,)\n"
     ]
    }
   ],
   "source": [
    "def prepare_image_data(base_path='resized_images', num_classes=16):\n",
    "    \"\"\"\n",
    "    Load images from folders 0-15 and prepare them with corresponding labels\n",
    "    for neural network training.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): Path to the directory containing class folders\n",
    "        num_classes (int): Number of class folders (0 to num_classes-1)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (images_array, labels_array) - NumPy arrays ready for neural network\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through each class folder\n",
    "    for class_idx in range(num_classes):\n",
    "        folder_path = os.path.join(os.getcwd(), base_path, str(class_idx))\n",
    "        \n",
    "        # Check if the folder exists\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: Folder {folder_path} does not exist. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Get all image files in the folder\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        print(f\"Loading {len(image_files)} images from class {class_idx}\")\n",
    "        \n",
    "        # Load each image\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            try:\n",
    "                # Read the image\n",
    "                img = cv2.imread(img_path)\n",
    "                \n",
    "                # Check if image was loaded successfully\n",
    "                if img is None:\n",
    "                    print(f\"Failed to load image: {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Add the image and its label to our lists\n",
    "                images.append(img)\n",
    "                labels.append(class_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images with shape {X.shape}\")\n",
    "    print(f\"Labels shape: {y.shape}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "image_data, label_data = prepare_image_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Georg\\anaconda3\\envs\\steam_analysis\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 4s/step - accuracy: 0.0893 - loss: 65.3663 - val_accuracy: 0.0513 - val_loss: 2.7766\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 4s/step - accuracy: 0.2551 - loss: 2.6807 - val_accuracy: 0.2051 - val_loss: 2.6303\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 7s/step - accuracy: 0.5989 - loss: 1.4764 - val_accuracy: 0.4103 - val_loss: 2.2710\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 8s/step - accuracy: 0.8500 - loss: 0.5666 - val_accuracy: 0.2564 - val_loss: 2.1831\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 4s/step - accuracy: 0.9393 - loss: 0.2111 - val_accuracy: 0.4103 - val_loss: 2.1028\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 5s/step - accuracy: 0.9816 - loss: 0.0546 - val_accuracy: 0.3590 - val_loss: 2.7323\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 5s/step - accuracy: 0.9957 - loss: 0.0410 - val_accuracy: 0.4615 - val_loss: 1.6806\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 5s/step - accuracy: 0.9933 - loss: 0.0261 - val_accuracy: 0.3846 - val_loss: 2.2887\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.3846 - val_loss: 2.4046\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 2.8979e-04 - val_accuracy: 0.4359 - val_loss: 2.2878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a6aea4ccd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    image_data, label_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Normalize the pixel values (important for neural networks)\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# 3. Convert the labels to one-hot encoding\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes=16)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, num_classes=16)\n",
    "\n",
    "# 4. Create the model with correct input shape\n",
    "model = keras.models.Sequential()\n",
    "# Add a Conv2D layer to reduce the image size before flattening (optional but recommended)\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1000, 660, 3)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dense(units=16, activation='softmax'))\n",
    "\n",
    "# 5. Compile the model correctly\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.categorical_crossentropy,  # Remove the parentheses\n",
    "    metrics=['accuracy']  # Use string instead of keras.metrics.Accuracy()\n",
    ")\n",
    "\n",
    "# 6. Fit the model with one-hot encoded labels\n",
    "# You might need to use a smaller batch size or downsample the images\n",
    "# if you encounter memory issues\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train_one_hot, \n",
    "    epochs=10, \n",
    "    batch_size=8,  # Smaller batch size due to large images\n",
    "    validation_data=(X_test, y_test_one_hot)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 15s - 7s/step - accuracy: 0.4359 - loss: 2.2878\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test_one_hot, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
